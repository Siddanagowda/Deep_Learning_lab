{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b27d45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Program - 3\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_d(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.w_i_h = np.random.randn(input_size, hidden_size)\n",
    "        self.b_h = np.random.randn(1, hidden_size)\n",
    "        self.w_h_o = np.random.randn(hidden_size, output_size)\n",
    "        self.b_o = np.random.randn(1, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.h_a = np.dot(x, self.w_i_h) + self.b_h\n",
    "        self.h_o = sigmoid(self.h_a)\n",
    "\n",
    "        self.o_a = np.dot(self.h_o, self.w_h_o) + self.b_o\n",
    "        self.o_o = softmax(self.o_a)\n",
    "\n",
    "        return self.o_o\n",
    "\n",
    "    def backward(self, x, y, output, lr):\n",
    "        m = y.shape[0]\n",
    "        d_o = output - y\n",
    "        e_h = d_o.dot(self.w_h_o.T)\n",
    "        d_h = e_h * sigmoid_d(self.h_o)\n",
    "\n",
    "        self.w_h_o -= self.h_o.T.dot(d_o) * lr / m\n",
    "        self.b_o -= np.sum(d_o, axis=0, keepdims=True) * lr /m\n",
    "        self.w_i_h -= x.T.dot(d_h) *lr / m\n",
    "        self.b_h -= np.sum(d_h, axis=0, keepdims=True) * lr /m\n",
    "\n",
    "    def loss_calculation(self, y_true, y_pred):\n",
    "        y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "        loss = -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
    "        return loss\n",
    "\n",
    "\n",
    "x = np.array([[0,0], [1,0], [0,1], [1,1]])\n",
    "y = np.array([[1,0,0], [0,1,0], [0,1,0], [0,0,1]])\n",
    "\n",
    "input_size, hidden_size, output_size = 2, 4, 3\n",
    "lr = 0.1\n",
    "epochs = 10000\n",
    "\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# train\n",
    "for i in range(epochs):\n",
    "    output = nn.forward(x)\n",
    "    nn.backward(x, y, output, lr)\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        loss = nn.loss_calculation(y, output)\n",
    "        print(f\"Epoch {i} | Loss {loss:.4f}\")\n",
    "\n",
    "print(\"predicting outputs \")\n",
    "prediction = nn.forward(x)\n",
    "print(prediction)\n",
    "\n",
    "print(\"\\npredicting classes \")\n",
    "print(np.argmax(prediction, axis=1))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
